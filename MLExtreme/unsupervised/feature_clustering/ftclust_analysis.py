import numpy as np
## TEMPORARY
import sys
import pdb
from . import utilities as ut
from ...utils.EVT_basics import round_signif

def setDistance_subface_to_matrix(subface, subfaces_matrix):
    """
    Calculates set distances `s` between one subface and a matrix of
    (binary encoded) subfaces.
    
    The set distance `s` between any two subfaces is defined as the
    ratio between the cardinalities of the symmetric difference and
    the union of the two sets.

    This is the key ingredient of the unsupervised performance
    criterion s(list_of_subsets, binary_encoded_new_point) proposed in [1]

    Args:
    - subface (np.ndarray): Single subface vector (binary vector), typically a test vector.
    - subfaces_matrix (np.ndarray): Matrix of reference subface vectors (binary entries) (typically, the ones estimated by damex or clef).

    Returns:
    - np.ndarray: Array of distances.

    References:
    ____________
        
    [1] Chiapino, M., Sabourin, A., & Segers, J. (2019). Identifying groups of
    variables with the potential of being large simultaneously.
    Extremes, 22, 193-222.

    """
    # try:
    # if normalize:
    result = (np.sum(abs(subface - subfaces_matrix), axis=1) /
              np.sum(subface + subfaces_matrix > 0, axis=1))
   
    # else:
    #     result = np.sum(abs(subface - subfaces_matrix), axis=1)
    # except Exception as e:
    #     print(f"Exception occurred: {e}")
    #     # Retrieve exception information and start post-mortem debugging
    #     ex_type, ex_value, ex_traceback = sys.exc_info()
    #     # return ex_traceback
    #     pdb.post_mortem(ex_traceback)

    return result


# def setDistance_subface_to_list(subface, subfaces_list, normalize=True):
#     """
#     Computes the pseudo-Subface distance between one subface and a
#     matrix of subfaces.

#     Args:
#     - subface (np.ndarray): Single subface vector.
#     - subfaces_list (list): list of subface vectors

#     Returns:
#     - np.ndarray: Array of distances.
#     """
#     subfaces_matrix = ut.subfaces_list_to_matrix(subfaces_list)
#     return setDistance_subface_to_matrix(subface, subfaces_matrix, normalize)
    
def setDistance_error_m2m(subfaces_matrix, masses, subfaces_reference_matrix,
                          reference_masses=None, expo_model=True, rate=10,):
    """Computes the average aggregated set distance between all rows of
    subfaces_matrix and the matrix subfaces_reference_matrix.

    The results is a weighted average of the aggregated set distances,
    weighted by the corresponding  rescaled `mass` entry in the
    considered subfaces in`subface_matrix'.

    If expo_model is True (default): agregation is done by considering
    a pseudo- likelihoood (density) of a row in subfaces_matrix,
    within a mixture model defined in the set of subfaces, as follows:

        -each row in subfaces_reference_matrix is a 'center of mass'
        -the references_masses are the  (unnormalized) weights of the mixture
    
        - Given that row_i in subfaces_matrix was generated by the mixture
            component reference_row_j in subfaces_reference_matrix, the set
            distance (see setDistance_subface_to_matrix) between row_i and
            reference_row_j follows an exponential distribution with rate
            `rate`. The likelihood term disregards any necessary normalizing
            constants, such as those accounting for the truncation of the
            exponential model or the combinatorial number of subfaces at a
            given set distance from reference_row_j

    in unsupervised usages: 
        -subfaces_reference_matrix is typically issued from prior
    estimation from damex or clef
        - subfaces_matrix is typically a dataset

    in supervised usage:
        both subfaces_matrix and subfaces_reference matrix are issued from a
        list of true or estimated subfaces and the goal is to assess the
        'distance'  between the two. 

    The lower, the better.

    """
    n_subfaces = np.shape(subfaces_matrix)[0]
    if n_subfaces == 0:
        return 0
    min_dists = 10 * np.ones(n_subfaces)
    if masses is None:
        weights = np.ones(n_subfaces)/n_subfaces
    else:
        if isinstance(masses, list):
            masses = np.array(masses)
        weights = masses / np.sum(masses)
    if not expo_model: 
        for i in range(n_subfaces):
            dists = setDistance_subface_to_matrix(subfaces_matrix[i],
                                                  subfaces_reference_matrix)
            
            min_dists[i] = np.min(dists)
            
    else:  # in this case return the deviance in a mixture model on subsets
        if reference_masses is None:
            nsub_ref = subfaces_reference_matrix.shape[0]
            reference_masses = np.ones(nsub_ref)/nsub_ref

        if isinstance(reference_masses, list):
            reference_masses = np.array(reference_masses)

        ref_weights = reference_masses / np.sum(reference_masses)
        for i in range(n_subfaces):
            dists = setDistance_subface_to_matrix(subfaces_matrix[i],
                                                  subfaces_reference_matrix)
            sum_value = np.sum(ref_weights * np.exp(- rate * dists))
          
            if sum_value > 0:
                min_dists[i] = - np.log(sum_value)
            else:
                # Handle the case where sum_value is zero
                min_dists[i] = np.inf  # or some other appropriate value
            #min_dists[i] = - np.log(np.sum(ref_weights * np.exp(- 15 * dists**2)))
                    
    return np.sum(min_dists * weights)


def setDistance_error(subfaces_list, masses, subfaces_reference_list,
                      reference_masses=None, dimension=None,
                      expo_model=True, rate=10
                      ):
    """
    Computes the average minimum set distance between
     all entries of subfaces_list and  the reference list
    subfaces_reference_list.

    The results is a weighted average of the minimum set distances,
    weighted by the corresponding normalized `mass` entry in the
    considered subfaces in `subfaces_list'

    The lower, the better.
    """
    if len(subfaces_list) == 0:
        return 0
    if len(subfaces_reference_list) == 0:
        return float('inf')
    subfaces_matrix = ut.subfaces_list_to_matrix(subfaces_list, dimension)
    subfaces_reference_matrix = ut.subfaces_list_to_matrix(
        subfaces_reference_list, dimension)
    return setDistance_error_m2m(subfaces_matrix, masses,
                                 subfaces_reference_matrix,
                                 reference_masses, expo_model, rate)


##################################
# For unsupervised evaluation ###

def setDistance_subfaces_data(subfaces_list,  threshold, std_data,
                              include_singletons=False, 
                              epsilon=None, masses=None, expo_model=True,
                              rate=10):
    """
    Calculates the average set Distance distance between a list of
    subfaces and a  matrix of rank transformed data. 

    Args:
    - subfaces (list): List of subfaces.
    - threshold (float): Radius for selection of extremes in std_data
    - std_data (np.ndarray): standardized data.
    - include_singletons: if False, disregards events where a single feature is large (suitable for analysisng concomittant events)
    
    Returns:
    - float: Average distance.
    """
    if len(subfaces_list) == 0:
        return float('inf')
    subfaces_matrix = ut.subfaces_list_to_matrix(subfaces_list,
                                                 dimension=std_data.shape[1])
    binary_data = ut.binary_large_features(std_data, threshold, epsilon=epsilon)
    if not include_singletons:
        id_keep_data = np.where(np.sum(binary_data, axis=1) >= 2)[0]
        binary_data = binary_data[id_keep_data]
        id_keep_estim = np.where(np.sum(subfaces_matrix, axis=1) >= 2)[0]
        subfaces_matrix = subfaces_matrix[id_keep_estim]       
        if masses is not None:
            if isinstance(masses, list):
                masses = np.array(masses)
            masses = masses[id_keep_estim]
         
    # data_to_estim =  np.mean([np.min(
    #     setDistance_subface_to_matrix(row, subfaces_matrix))
    #                           for row in binary_data])
    # )]
    data_to_estim = setDistance_error_m2m(
        subfaces_matrix=binary_data, masses=None,
        subfaces_reference_matrix=subfaces_matrix, 
        reference_masses=masses, expo_model=expo_model,
        rate=rate
    )
 
    return  data_to_estim # max(estim_to_data, data_to_estim)
    


# ################################
# ##### previously in damex

def list_to_dict_size(faces_list, mass_list=None):
    """Converts a list of faces into a dictionary where keys are face
    sizes and values are lists of faces, ordered by sizes.
    
    
    Useful for inspection of large lists of subfaces. 

    Parameters:

    - faces_list (list of lists): A list where each element is a list
      of points representing a face.
    - mass_list (list): optional. if provided the function 
    Returns:

    - faces_dict: A dictionary where the key is the size of the face and the
      value is a list of faces of that size.
    - mass_dict: a dictionary with same keys as faces_dict and the values are the masses associated with the corresponding subfaces in faces_dict

    """
    if len(faces_list)==0:
        return {}, {}
    # Initialize dictionary with sizes ranging from 1 to the maximum face size
    faces_dict = {size: [] for size in range(1, max(map(len, faces_list)) + 1)}
    mass_dict = {size: [] for size in range(1, max(map(len, faces_list)) + 1)}
    # Populate the dictionary with faces based on their sizes
    # for face in faces_list:
    #     faces_dict[len(face)].append(face)

    for index, face in enumerate(faces_list): 
        faces_dict[len(face)].append(face)
        if mass_list is not None:
            mass_dict[len(face)].append(round_signif(mass_list[index],2))

    return faces_dict, mass_dict






